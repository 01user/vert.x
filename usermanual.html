<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
    "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
  <link href="bootstrap/bootstrap.css" type="text/css" rel="stylesheet"/>

  <link href="google-code-prettify/prettify.css" type="text/css" rel="stylesheet"/>
  <script type="text/javascript" src="google-code-prettify/prettify.js"></script>
  <style type="text/css">
    body {
      padding-top: 60px;
      padding-bottom: 40px;
    }
  </style>
  <!--
  <script type='text/javascript' src='http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js'></script>
  <script type='text/javascript' src='css/bootstrap-tabs.js'></script>
  -->
  <title>vert.x</title>
</head>

<body onload="prettyPrint()">

<div class="navbar navbar-fixed-top">
  <div class="navbar-inner">
    <div class="container">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="i-bar"></span>
        <span class="i-bar"></span>
        <span class="i-bar"></span>
      </a>
      <a class="brand" href="#">vert.x</a>

      <div class="nav-collapse">
        <ul class="nav">
          <li class="active"><a href="#">Home</a></li>
          <li><a href="#about">About</a></li>
          <li><a href="#contact">Contact</a></li>
        </ul>
      </div>
      <!--/.nav-collapse -->
    </div>
  </div>
</div>

<div class="container">

  <!-- Main hero unit for a primary marketing message or call to action -->
  <div class="hero-unit">
    <h1>vert.x User Manual</h1>

    <p>Blah blah blah</p>
  </div>

  <!-- Example row of columns -->
  <div class="row">
    <div class="span9">
<div>
<h1>User Manual</h1><br/>

<h2>Introduction</h2><br/>

<h3>What is vert.x?</h3><br/>

<p>vert.x is a framework for creating massively scalable, concurrent, real-time, web-enabled applications.  </p>

<p>Some key features:</p>

<ul>
<li><p>Polyglot. Write your application in JavaScript, Java or Ruby. It's up to you. Or mix and match several programming languages in a single application.</p></li>
<li><p>No more worrying about concurrency. vert.x allows you to write all your code as single threaded, freeing you from the hassle of multi-threaded programming.</p></li>
<li><p>An asynchronous, event based API so your applications can scale seamlessly across many cores with just a few threads.</p></li>
<li><p>Distributed event bus that spans the client and server side so your applications components can communicate incredibly easily.</p></li>
</ul>

<h2>Concepts in vert.x</h2><br/>

<p>In this section I'd like to give an overview of what the different conceptual part of vert.x are and how they hang together. Many of this concepts will be discussed in more depth later on in this manual.</p>

<h3>Verticle</h3><br/>

<p>The atomic unit in vert.x is called a <em>verticle</em> (Like a particle, but in vert.x). Verticles can be written in JavaScript, Ruby or Java. A verticle is defined by having a <em>main</em> which is just the script (or class in the case of Java) to run to start the verticle.</p>

<p>Your application may contain just one verticle, or it could consist of a whole set of verticles communicating with each other using the event bus.</p>

<p>Verticles run inside <em>vert.x server instance</em>. </p>

<p><strong>TODO details on how to write a verticle in each language and vertxStop()</strong></p>

<h3>Vert.x Instances</h3><br/>

<p>Verticles run inside vert.x instances. A single vert.x instance is basically an operating system process running a JVM. There can be many verticle instances running inside a single vert.x instance at any time. vert.x makes sure each vert.x instance is isolated by giving it its own classloader so they can't interact by sharing static members, global variables or other means.</p>

<p>There can be many vert.x instances running on the same host, or on different hosts on the network at the same time. The instances can be configured to cluster with each other forming a distributed event bus over which verticle instances can communicate.</p>

<h3>Polyglot</h3><br/>

<p>We want you to be able to develop your verticles in a choice of programming languages. Never have developers had such a choice of great languages, and we want that to be reflected in the languages we support. vert.x allows you to mix and match verticles written in different languages in the same application. Currently we support JavaScript, Ruby and Java, but we aim to support Groovy, Clojure, Scala and Python going ahead.</p>

<h3>Concurrency</h3><br/>

<p>The vert.x instance guarantees that a particular verticle instance is always executed by the exact same thread. This gives you a huge advantage as a developer, since you can program all your code as single threaded. Well, that won't be a big deal to you if you are coming from JavaScript where everything is single threaded, but if you're used to multi-threaded programming in Java, Scala, or even Ruby, this may come as a huge relief!</p>

<p>Gone are the days of worrying about race conditions, locks, mutexes, volatile variables and synchronization. </p>

<h3>Event-based Programming Model</h3><br/>

<p>Most things you do in vert.x involve setting event handlers. E.g. to receive data from a TCP socket you set a handler - the handler is then called when data arrives. You also set handlers to receive messages from the event bus, to receive HTTP requests and responses, to be notified when a connection is closed, or to be notified when a timer fires. There are many examples throughout the vert.x api.</p>

<p>In other words, vert.x provides an event-based programming model. </p>

<p>Any other operations in vert.x that don't involve handlers, e.g. writing some data to a socket are guaranteed never to block.</p>

<p><em>Why is it done this way?</em></p>

<p>The answer is: If we want our application to scale with many connections, <em>we don't have a choice</em>.</p>

<p>Let's imagine that the vert.x api allowed a blocking read on a TCP socket. When the code in a verticle called that blocking operation and no data arrived for, say, 1 minute, it means that thread cannot do anything else during that time - it can't do work for any other verticle.</p>

<p>For such a blocking model to work and the system to remain responsive, each verticle instance would need to be assigned its own thread. Now consider what happens when we have thousands, 10s of thousands, or 100s of thousands of verticles running. We clearly can't have that many threads - the overhead due to context switching and stack space would be horrendous. It's clear to see such a blocking model just doesn't scale.</p>

<p>The only way to make it scale is have a 100% non blocking api. There are two ways to do this:</p>

<ul>
<li><p>Used an asynchronous, event based API. Let the system call you when events occur. Do not block waiting for things to happen.</p></li>
<li><p>Use some kind of co-routine approach. Co-routines allow you to suspend the execution of a piece of code and come back to a later when an event occurs. However co-routines are not currently supported across the different languages, or versions of languages that we support in vert.x</p></li>
</ul>

<p>vert.x currently takes the event-based api approach. As support for coroutines in various languages matures we will consider also supporting a co-routine based approach in the api.</p>

<h3>Event Loops</h3><br/>

<p>Internally, the vert.x instance manages a small set of threads, typically matching the number of threads to the available cores on the server. We call these threads event loops, since they basically just loop around (well... they do actually go to sleep if there is nothing to do) seeing if there is any work to do, e.g. reading some data from a socket, or executing a timer.</p>

<p>When a verticle instance is deployed, the server chooses an event loop which will be assigned to that instance. Any subsequent work to be done for that instance will always be dispatched using that thread. Of course, since there are potentially many thousands of verticles running at any one time, a single event loop is assigned to many verticles at the same time.</p>

<p>We call this the <em>multi-reactor pattern</em>. It's like the [reactor pattern] (http://en.wikipedia.org/wiki/Reactor_pattern) but there's more than one event loop.</p>

<h3>Message Passing</h3><br/>

<p>Verticles can communicate with other verticles running in the same, or different, vert.x instance using the event bus. Each verticle instance is single threaded so in some ways it resembles the <a href="http://en.wikipedia.org/wiki/Actor_model">actor model</a> popularised by the Erlang programming language. However there are some difference, for example, each verticle can set multiple event handlers, rather than having a single mail-box. You can think of the vert.x model as a superset of the actor model.</p>

<p>By having many verticle instances in a vert.x server instance and allowing message passing allows the system to scale well over available cores without having to allow multi-threaded execution of any verticle code.</p>

<h3>Shared data</h3><br/>

<p>Message passing is great, but its not always the best approach to concurrency for certain applications. Consider an application that wishes to provide an in memory web cache. As requests come in to the server, the server looks up the request in the cache and returns it from there if the item is present, if the item is not present it loads it from disk and places it in the cache for the next time.</p>

<p>We want this system to scale across available cores. Modelling this using message passing is problematic. At one end of the scale we could have a single verticle that manages the cache, but this means all requests to the cache will be serialized through a single threaded verticle instance. We could improve things by having multiple instances of the verticle managing different parts of the cache, but it quickly gets ugly and complicated.</p>

<p>Such a use case is better solved by providing a shared map structure that can be accessed directly by different verticle instances in the same vert.x instance. As requests come in, the data can be efficiently looked up in the cache with a single line of code and returned to the user.</p>

<p>It's fashionable these days to deride shared data. But shared data is only dangerous if the data that you share is mutable.</p>

<p>vert.x provides a shared map and shared set facility which allows only <em>immutable</em> data to be shared between verticles.</p>

<h3>Blocking and Long Running Operations</h3><br/>

<p>Considering vert.x uses only a small number of event loop threads, and considering that vert.x has to dispatch events to potentially thousands of verticles, and remain responsive, it's pretty clear that those threads can't hang around in any verticle event handler for too long - if they do it means that event loop can't service events for any other verticle, and everything can grind to a halt.</p>

<p>What does <em>hanging around</em> mean? It means anything that can take more than a few milliseconds of <em>wall-clock</em> time. (That's real actual time, not CPU time). That includes things like  the thread sleeping or blocking on a database operation which don't involve much CPU time, but it also involves <em>busy waits</em> such as a computationally intensive operation, e.g. factorising prime numbers.</p>

<h3>Worker Verticles</h3><br/>

<p>By default verticles event handlers should not take a long time to execute, however there are cases where you can't avoid blocking, or you genuinely have computationally intensive operations to perform.</p>

<p>An example of the former would be calling a third-party blocking database API from a verticle. In this case you don't have control of the client library you are using so you just have to block until you get the result back.</p>

<p>Another example would be a worker verticle which needs to do an intensive calculation like calculating Fibonacci numbers. In such a case the calculation could be done a little at a time, and event handlers set to continue the calculation the next time around the event loop, but this is awkward, and just a little bit silly ;)</p>

<p>For cases like these, vert.x allows you to mark a particular verticle instance as a <em>worker verticle</em>. A worker verticle differs from a normal verticle in that it is not assigned a vert.x event loop thread, but instead it executes on a thread from an internal thread pool that vert.x maintains called the <em>background pool</em>. </p>

<p>Worker verticles are never executed concurrently by more than one thread. Worker verticles are also not allowed to use TCP or HTTP clients or servers. Worker verticles normally communicate with other verticles using the vert.x event bus, e.g. receiving work to process.</p>

<p>Worker verticles should be kept to a minimum, since a blocking approach doesn't scale if you want to deal with many concurrent connections. We'll talk more about worker verticles later on.</p>

<p><strong>TODO more stuff on how to write a worker</strong></p>

<h3>Code is Config</h3><br/>

<p><strong>TODO</strong></p>

<h3>Core and BusMods</h3><br/>

<p><strong>TODO</strong></p>

<h2>Installation</h2><br/>

<p>Before you can do anything with vert.x you need to install it, so let's get that out of the way.</p>

<h3>Getting a distro</h3><br/>

<p>You can't install it if you haven't got it, so first you need to download it.  </p>

<p>The easiest way is to download a distro from the download page [link]. Alternatively you can build from source. To do that see the instructions on the github wiki.</p>

<h3>Pre-requisites</h3><br/>

<ul>
<li><p>Operating System. vert.x runs out of the box on Linux or OSX. If you are running Windows, the best way to run vert.x is to create a Linux (I recommend Ubuntu) vitrtual machine using your favourite virtualisation software (VMware Workstation, of course!) and run it in that.</p></li>
<li><p>JDK. vert.x requires JDK 1.7.0 or later. You can use the official Oracle distribution or the OpenJDK version. Make sure the JDK bin directory is on your <code>PATH</code>.</p></li>
<li><p>Apache Ant. If you want to run the Java examples you will need Apache Ant installed. Otherwise you don't need it.</p></li>
<li><p>Ruby. If you want to deploy Ruby verticles then you will need JRuby 1.6.4 later installed. Please set the <code>JRUBY_HOME</code> environment variable to point at the base of the JRuby installation. If you don't intend to deploy Ruby verticles you can ignore this.</p></li>
</ul>

<h3>Install vert.x</h3><br/>

<p>Once you've got the pre-requisites installed, you install vert.x by;</p>

<ol>
<li>Unzip the distro somewhere sensible (e.g. your home directory) </li>
<li>Add the vert.x <code>bin</code> directory to your <code>PATH</code>.</li>
</ol>

<p>To make sure you've installed it correctly, open another console and type:</p>

<pre class="prettyprint">tim@Ethel:~/example$ vertx version
vert.x 1.0.0.beta.1
</pre>

<p>You should see output something like the above.    </p>

<p>That's it, the boring stuff is out of the way. Now you're ready to go!</p>

<h2>Running vert.x</h2><br/>

<p><em>Note on terminology: A *verticle* is the name we've given to the components that you write and deploy to vert.x. Think of it like a 'particle', but for vert.x</em></p>

<p>There are various ways vert.x verticles can be run so let's dive in with a real example. Iny my experience most people learn better by example than by reading through pages of instructions.</p>

<h3>Running a verticle in its own vert.x instance</h3><br/>

<p>The <code>vertx</code> command is used to run vert.x verticles as well as start and stop vert.x standalone servers and deploy and undeploy verticles to standalone server (we'll get to the standalone server stuff a bit later on. If you just type <code>vertx</code> at a command line you can see all the various different options the command takes.</p>

<p>In particular <code>vertx run</code> is used to start a vert.x verticles in <em>its own instance</em> of a vert.x server. This is the simplest way to run a verticle.</p>

<p>At minimum <code>vertx run</code> takes a single parameter - the name of the main to run. If it's a JavaScript or Ruby verticle then it's just the name of the script, e.g. <code>server.js</code> or <code>server.rb</code>. (it doesn't have to be called server, you can name it anything as long as it has the right extension). If it's Java the main is the fully qualified class name of the main classs.</p>

<p>The <code>vertx run</code> command can take a few optional parameters, they are:</p>

<ul>
<li><p><code>-cp &lt;path&gt;</code> The path on which to search for the main and any other resources used by the verticle. This defaults to <code>.</code> (current directory). If your verticles references other scripts, classes or other resources (e.g. jar files) then make sure these are on this path. The path can contain multiple path entries separated by <code>:</code> (colon). Each path entry can be an absolute or relative path to a directory containing scripts, or absolute or relative filenames for jar or zip files.
An example path might be <code>-cp classes:lib/otherscripts:jars/myjar.jar:jars/otherjar.jar</code>
Always use the path to reference any resources that your verticle requires. Please, <strong>do not</strong> put them on the system classpath as this can cause isolation issues between deployed verticles.</p></li>
<li><p><code>-instances &lt;instances&gt;</code> The number of instances of the verticle to instantiate in the vert.x server. Each verticle instance is strictly single threaded so to scale your application across available cores you might want to deploy more than one instance. If ommitted a single instance will be deployed. We'll talk more about scaling, later on in this user manual [LINK].</p></li>
<li><p><code>-worker</code> This options determines whether the verticle is a worker verticle or not. Default is false (not a worker). This is discussed in detail later on in the manual. [LINK]   </p></li>
<li><p><code>-cluster</code> This option determines whether the vert.x server which is started will attempt to form a cluster with other vert.x instances on the network. Clustering vert.x instances allows vert.x to form a distributed event bus with other nodes. Default is false (not clustered). This is discussed in detail in the chapter on clustering [LINK].</p></li>
<li><p><code>-cluster-port</code> If the <code>cluster</code> option has also been specified then this determines which port will be used for cluster communication with other vert.x instances. Default is <code>25500</code>. If you are running more than one vert.x instance on the same host and want to cluster them, then you'll need to make sure each instance has its own cluster port so avoid port conflicts.</p></li>
<li><p><code>-cluster-host</code> If the <code>cluster</code> option has also been specified then this determines which host addresses  will be used for cluster communication with other vert.x instances. Default is <code>0.0.0.0</code> (all available interfaces).</p></li>
</ul>

<p>Here are some examples of <code>vertx run</code>:</p>

<p>Run a JavaScript verticle server.js</p>

<pre class="prettyprint">vertx run server.js
</pre>

<p>Run 10 instances of a Java verticle specifying classpath</p>

<pre class="prettyprint">vertx run com.acme.MyVerticle -cp "classes:lib/myjar.jar" -instances 10
</pre>

<p>Run 20 instances of a ruby worker verticle    </p>

<pre class="prettyprint">vertx run order_worker.rb -instances 20 -worker
</pre>

<p>Run two JavaScript verticles on the same machine and let them cluster together with each other and any other servers on the network</p>

<pre class="prettyprint">vertx run handler1.js -cluster
vertx run handler1.js -cluster -cluster-port 25501
</pre>

<h3>Running a verticle in a standalone vert.x server</h3><br/>

<p>Often you may have several verticles that make up your application - you could just start up each one in its own vert.x instance by using a separate <code>vertx run</code> for each verticle and have them communicate using the distributed event bus, but it might be a bit wasteful to have each one running in is own JVM instance.</p>

<p>In such cases it often makes sense to start up a standalone vert.x instance and deploy verticles to that instance instead.</p>

<p>This can be done using the <code>vertx start</code> and <code>vertx deploy</code> commands. Let's do that now, using the same <code>server.js</code> we created in the previous section.</p>

<h4>Starting a Standalone vert.x server</h4><br/>

<p>To start a standalone vert.x server you simply type the command:</p>

<pre class="prettyprint">vertx start
</pre>

<p>The <code>vertx start</code> command also takes a few optional parameters, some of which have the same meaning as the corresponding parameter in the <code>vertx run</code> command:</p>

<ul>
<li><p><code>-port</code> This specifies which port the server will listen to for deployments. Default is <code>25571</code>. You'd want to change this if you had multiple standalone vert.x servers running on the same host. </p></li>
<li><p><code>-cluster</code> This has the same meaning of the <code>-cluster</code> parameter in <code>vertx run</code>. </p></li>
<li><p><code>-cluster-port</code> This has the same meaning of the <code>-cluster-port</code> parameter in <code>vertx run</code>. </p></li>
<li><p><code>-cluster-host</code> This has the same meaning of the <code>-cluster-host</code> parameter in <code>vertx run</code>. </p></li>
</ul>

<p>Here are some examples:</p>

<p>Start a clustered vert.x server:</p>

<pre class="prettyprint">vertx start -cluster
</pre>

<p>Start two unclustered vert.x servers on the same host - they need to be given unique deployment ports</p>

<pre class="prettyprint">vertx start
vertx start -port 25572
</pre>

<p>Start two clustered vert.x servers on the same host - they need to be given unique deployment and clustering ports </p>

<pre class="prettyprint">vertx start -cluster
vertx start -cluster -port 25572 -cluster-port 25501
</pre>

<h4>Deploying a Verticle to a Standalone server</h4><br/>

<p>Once you have a vert.x standalone server running, you can deploy verticles to it. This is done using the <code>vertx deploy</code> command.</p>

<p>Any verticles deployed to a standalone server are transient and only last as long as the server is running. You can have as many verticles as you like (subject to available RAM) deployed in the same instance at the same time. The verticles can be in a mixture of languages.</p>

<p>Each verticle instance runs in its own classloader so is isolated from any other verticles running in the instance at the same time. You'll hear about verticle can communicate with each other using shared data and the event bus later on.</p>

<p>The <code>vertx deploy</code> command can take a few optional parameters, (some have the same meaning as the parameter with the same name in <code>vertx run</code>), they are:</p>

<ul>
<li><p><code>-name</code>. A name to give the deployment. This is subsequently used when undeploying the deployment. If you don't specify a name one will be generated for you, and displayed when you deploy.</p></li>
<li><p><code>-port</code> This specifies which port it will attempt to connect to the server on, to deploy the verticle. Default is <code>25571</code>.  </p></li>
<li><p><code>-cp &lt;path&gt;</code> This has the same meaning of the <code>-cp</code> parameter in <code>vertx run</code>.</p></li>
<li><p><code>-instances &lt;instances&gt;</code> This has the same meaning of the <code>-instances</code> parameter in <code>vertx run</code>.</p></li>
<li><p><code>-worker</code> This has the same meaning of the <code>-worker</code> parameter in <code>vertx run</code>.</p></li>
</ul>

<p>Here are some examples:</p>

<p>Deploy a JavaScript verticle server.js</p>

<pre class="prettyprint">vertx deploy server.js
</pre>

<p>Deploy 10 instances of a Java verticle specifying classpath, to a vert.x server instance on port 25600</p>

<pre class="prettyprint">vertx deploy com.acme.MyVerticle -cp "classes:lib/myjar.jar" -instances 10 -port 25600
</pre>

<p>Deploy 20 instances of a ruby worker verticle    </p>

<pre class="prettyprint">vertx deploy order_worker.rb -instances 20 -worker
</pre>

<p>Deploy a Ruby verticle specifying a name, then undeploy it</p>

<pre class="prettyprint">vertx deploy my_verticle.rb -name my_app
vertx undeploy my_app
</pre>

<h4>Undeploying Verticles</h4><br/>

<p>To undeploy verticles previously deployed using <code>vertx deploy</code> you simply type: <code>vertx undeploy &lt;name&gt;</code>, where <code>name</code> is the name the deployment that you specified using the <code>-name</code> parameter, or was generated for you, at deployment time.</p>

<p>Examples:</p>

<p>Undeploy using name specified when deploying</p>

<pre class="prettyprint">vertx undeploy my_app
</pre>

<p>Undeploy using generated name which was displayed when deploying    </p>

<pre class="prettyprint">vertx undeploy app-132855b0-a4ef-4fcf-ad3c-9c6762d2e518
</pre>

<h4>Stopping a Standalone vert.x server</h4><br/>

<p>To stop a vert.x standalone server you use the command <code>vertx stop</code>. This will cause the server to exit.</p>

<p>The <code>vertx stop</code> command can take an optional parameter:</p>

<ul>
<li><code>-port</code> This specifies which port it will attempt to connect to the server on, to stop the server. Default is <code>25571</code>. If you have more than one vert.x server on localhost then you use this parameter to determine which one to stop.</li>
</ul>

<h2>Writing Verticles</h2><br/>

<p>We previously discussed how a Verticle was the atomic unit in vert.x, and the unit of deployment. We discussed that verticles can be written in several different programming languages and deployed to the same or different servers. Let's look in more detail about how to write a verticle.</p>

<p>Take a look at the simple TCP echo server verticle again.</p>

<h3>JavaScript</h3><br/>

<p>The main JavaScript script must call <code>load('vertx.js')</code> to load the vertx global which contains the api.</p>

<p>The <code>load</code> function is also used if you want to load any other JavaScript scripts you have in your verticle.</p>

<p>The main script is simply run when the verticle is deployed.</p>

<p>The optional function <code>vertxStop</code> is called when the verticle is undeployed. This is an optional function that should be used if your verticle needs to do any clean-up, such as shutting down servers or clients or unregistering handlers. </p>

<pre class="prettyprint">load('vertx.js')

var server = new vertx.NetServer();

server.connectHandler(function(sock) {
  new vertx.Pump(sock, sock).start();
}).listen(1234, 'localhost');

function vertxStop() {
  server.close();
}
</pre>

<h3>Ruby</h3><br/>

<p>All scripts in your Ruby verticle should <code>require 'vertx'</code> in order to load the vert.x api  </p>

<p>The main script is simply run when the verticle is deployed.</p>

<p>The optional method <code>vertx_stop</code> is called when the verticle is undeployed. This is an optional function that should be used if your verticle needs to do any clean-up, such as shutting down servers or clients or unregistering handlers.   </p>

<pre class="prettyprint">require "vertx"
include Vertx

@server = NetServer.new.connect_handler { |socket|
  Pump.new(socket, socket).start
}.listen(1234)

def vertx_stop
  @server.close
end
</pre>

<h3>Java</h3><br/>

<p>Java is not a scripting language so vert.x can't just <em>execute the class</em> in order to start the verticle. All Java verticles must implement the interface <code>org.vertx.java.core.app.VertxApp</code>. This interface has a method <code>start()</code> which is called when the verticle is deployed and a method <code>stop()</code> which is called when the verticle is undeployed.</p>

<pre class="prettyprint">import org.vertx.java.core.Handler;
import org.vertx.java.core.app.VertxApp;
import org.vertx.java.core.net.*;
import org.vertx.java.core.streams.Pump; 

public class EchoServer implements VertxApp {

  private NetServer server;

  public void start() {
    server = new NetServer().connectHandler(new Handler&lt;NetSocket&gt;() {
      public void handle(final NetSocket socket) {
        new Pump(socket, socket).start();
      }
    }).listen(1234);
  }

  public void stop() {
    server.close();
  }
}
</pre>

<h2>The Event Bus</h2><br/>

<p>The event bus is the nervous system of vert.x. It allows verticles to communicate each other irrespective of whether they're in the same vert.x instance, or in a different vert.x instance. It even allows client side JavaScript running in a browser to communicate with verticles. More on that later.</p>

<p>The event bus API is incredibly simple. It basically involves registering handlers, unregistering handlers and sending messages.</p>

<p>First some preliminaries:</p>

<h3>The Theory</h3><br/>

<h4>Addressing</h4><br/>

<p>Messages are sent on the event bus to an <em>address</em>. vert.x doesn't bother with any fancy addressing schemes. In vert.x an address is simply an arbitrary string, although it is wise to use some kind of scheme, e.g. using periods to demarcate a namespace.</p>

<p>Some examples of valid addresses are <code>europe.news.feed1</code>, <code>acme.games.pacman</code>, <code>sausages</code>, and <code>X</code>. </p>

<h4>Handlers</h4><br/>

<p>You register a handler at an address. The handler will be called when any messages which have been sent to that address have been received. Many different handlers from the same or different verticles can be registered at the same address. A single handler can be registered by the verticle at many different addresses.</p>

<p>When a message is received in a handler, and has been <em>processed</em>, the receiver can optionally decide to reply to the message. If they do so, and the message was sent specifying a reply handler, that reply handler will be called.</p>

<h4>Sending messages</h4><br/>

<p>You send a message by specifying the address and telling the event bus to send it there. The event bus will then deliver the message to any handlers registered at that address. If multiple vert.x instances are clustered together, the message will be delivered to any matching handlers irrespective of what vert.x instance they reside on.  </p>

<p>The vert.x event bus is therefore an implementation of <em>Publish-Subscribe Messaging</em>.</p>

<p>When sending a message you can specify an optional reply handler which will be invoked once the message has reached a handler and the recipient has replied to it.</p>

<p>The vert.x event bus therefore also implements the <em>Request-Response</em> messaging pattern.</p>

<p>All messages in the event bus are transient, and in case of failure of all or parts of the event bus, there is every chance the message will be lost. If your application cares about lost messages, you should code your handlers to be idempotent, and your senders to retry after recovery.</p>

<p>Messages that you send on the event bus can be as simple as a string, a number or a boolean. You can also send vert.x buffers [LINK] or JSON Messages [LINK]. If your messages are more than trivial, it's a common convention in vert.x to use JSON messages to communicate between verticles. JSON is easy to create and parse in all the languages that vert.x supports.</p>

<h3>Event Bus API</h3><br/>

<h4>JavaScript</h4><br/>

<h5>Registering and Unregistering Handlers</h5><br/>

<p>To set a message handler on the address <code>test.address</code>, you do the following:</p>

<pre class="prettyprint">var eb = vertx.EventBus;

var myHandler = function(message)) {
  log.println('I received a message ' + message);
}

eb.registerHandler('test.address', myHandler);
</pre>

<p>It's as simple as that. The handler will then receive any messages sent to that address.</p>

<p>When you register a handler on an address and you're in a cluster it can take some time for the knowledge of that new handler to be propagated across the entire to cluster. If you want to be notified when that has happened you can optionally specify another function to the <code>registerHandler</code> function as the third argument. This function will then be called once the information has reached all nodes of the cluster. E.g. :</p>

<pre class="prettyprint">eb.registerHandler('test.address', myHandler, function() {
    log.println('Yippee! The handler info has been propagated across the cluster';
});
</pre>

<p>To unregister a handler it's just as straightforward. You simply call <code>unregisterHandler</code> passing in the address and the handler:</p>

<pre class="prettyprint">eb.unregisterHandler('test.address', myHandler);
</pre>

<p>A single handler can be registered multiple times on the same, or different addresses so in order to identify it uniquely you have to specify both the address and the handler. </p>

<p>Like with registering, when you unregister a handler and you're in a cluster it can also take some time for the knowledge of that new handler to be propagated across the entire to cluster. If you want to be notified when that has happened you can optionally specify another function to the registerHandler as the third argument. E.g. :</p>

<pre class="prettyprint">eb.unregisterHandler('test.address', myHandler, function() {
    log.println('Yippee! The handler unregister has been propagated across the cluster';
});
</pre>

<p><em>Make sure you unregister any handlers in the vertxStop() method of your verticle, to avoid leaking handlers</em>    </p>

<h5>Sending messages</h5><br/>

<p>Sending a message is also trivially easy. Just send it specifying the address you want to send it to, for example:</p>

<pre class="prettyprint">eb.send('test.address', 'hello world');
</pre>

<p>That message will then be delivered to any handlers registered against the address <code>test.address</code>. If you are running vert.x in cluster mode then it will also be delivered to any handlers on that address irrespective of what vert.x instance they are in.</p>

<p>The message you send can be any of the following types: </p>

<ul>
<li>number</li>
<li>string</li>
<li>boolean</li>
<li>JSON object</li>
<li>vert.x Buffer</li>
</ul>

<p>Here are some more examples:</p>

<p>Send some numbers:</p>

<pre class="prettyprint">eb.send('test.address', 1234);    
eb.send('test.address', 3.14159);
</pre>

<p>Send a boolean:</p>

<pre class="prettyprint">eb.send('test.address', true);
</pre>

<p>Send a JSON object:</p>

<pre class="prettyprint">var myObj = {
  name: 'Tim'
  address: 'The Moon'
  age: 457    
}
eb.send('test.address', myObj);
</pre>

<p>Null messages can also be sent:</p>

<pre class="prettyprint">eb.send('test.address', null);
</pre>

<p>It's a good convention to have your verticles communicating using JSON.</p>

<h4>Replying to messages</h4><br/>

<p>Sometimes after you send a message you want to receive a reply from the recipient. This is known as the <em>request-response pattern</em>.</p>

<p>To do this you send a message, specifying a reply handler as the third argument. When the receiver receives the message they are passed a replier function as the second parameter to the handler. When this function is invoked it causes a reply to be sent back to the sender where the reply handler is invoked. An example will make this clear:</p>

<p>The receiver:</p>

<pre class="prettyprint">var myHandler = function(message, replier) {
  log.println('I received a message ' + message);

  // Do some stuff

  // Now reply to it

  replier('This is a reply');
}

eb.registerHandler('test.address', myHandler);
</pre>

<p>The sender:</p>

<pre class="prettyprint">eb.send('test.address', 'This is a message', function(reply) {
    log.println('I received a reply ' + reply);
});
</pre>

<p>It is legal also to send an empty reply or null reply.</p>

<h4>Distributed event bus</h4><br/>

<p>To make each vert.x instance on your network participate on the same event bus, start each vert.x instance with the <code>-cluster</code> command line switch.</p>

<p>See the chatper on <em>running vert.x</em> [LINK] for more information on this.    </p>

<h2>Writing TCP Servers and Clients</h2><br/>

<p>Creating TCP servers and clients is incredibly easy with vert.x.</p>

<h3>Net Server</h3><br/>

<h4>Creating a Net Server</h4><br/>

<p>To create a TCP server we simply create an instance of vertx.net.NetServer.</p>

<pre class="prettyprint">var server = new vertx.NetServer();
</pre>

<h4>Start the Server Listening</h4><br/>

<p>To tell that server to listen on for incoming connections we do:    </p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.listen(1234, 'myhost');
</pre>

<p>The first parameter to <code>listen</code> is the port. The second parameter is the hostname or ip address. If it is ommitted it will default to <code>0.0.0.0</code> which means it will listen at all available interfaces.</p>

<h4>Getting Notified of Incoming Connections</h4><br/>

<p>Just having a net server listening creates a working server that you can connect to (try it with telnet!), however it's not very useful since it doesn't do anything with the connections. To be notified when a connection occurs we need call the  <code>connectHandler</code> function of the server, passing in a handler:</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {
  log.println('A client has connected!');
})  

server.listen(1234, 'localhost');
</pre>

<p>That's a bit more interesting. Now it displays 'A client has connected!' every time a client connects.   </p>

<p>The return value of the <code>connectHandler</code> method is the server itself, so multiple invocations can be chained together. That means we can rewrite the above with:</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {
  log.println('A client has connected!');
}).listen(1234, 'localhost');
</pre>

<p>This is a common pattern throughout the vert.x api.    </p>

<h4>Closing a Net Server</h4><br/>

<p>To close a net server just call the <code>close</code> function.</p>

<pre class="prettyprint">server.close();
</pre>

<p>The close is actually asynchronous and might not complete until some time after the <code>close</code> function has returned. If you want to be notified when the actual close has completed then you can pass in a function to the <code>close</code> function. This handler will then be called when the close has fully completed.</p>

<pre class="prettyprint">server.close(function() {
  log.println('The server is now fully closed.');
});
</pre>

<h4>NetServer Properties</h4><br/>

<p>NetServer has a set of properties you can set which affect its behaviour. Firstly there are bunch of properties used to tweak the TCP parameters, in most cases you won't need to set these:</p>

<ul>
<li><p><code>setTCPNoDelay(tcpNoDelay)</code> If <code>tcpNoDelay</code> is true then <a href="http://en.wikipedia.org/wiki/Nagle's_algorithm">Nagle's Algorithm</a> is disabled. If false then it is enabled.</p></li>
<li><p><code>setSendBufferSize(size)</code> Sets the TCP send buffer size in bytes.</p></li>
<li><p><code>setReceiveBufferSize(size)</code> Sets the TCP received buffer size in bytes.</p></li>
<li><p><code>setTCPKeepAlive(keepAlive)</code> if <code>keepAlive</code> is true then <a href="http://en.wikipedia.org/wiki/Keepalive#TCP_keepalive">TCP keep alive</a> is enabled, if false it is disabled. </p></li>
<li><p><code>setReuseAddress(reuse)</code> if <code>reuse</code> is true then addresses in TIME_WAIT state can be reused after they have been closed.</p></li>
<li><p><code>setSoLinger(linger)</code></p></li>
<li><p><code>setTrafficClass(trafficClass)</code></p></li>
</ul>

<p>NetServer has a further set of properties which are used to configure SSL. We'll discuss those later on.</p>

<h4>Handling Data</h4><br/>

<p>So far we have seen how to create a NetServer, and accept incoming connections, but not how to do anything interesting with the connections, let's do that now.</p>

<p>When a connection is made, the connect handler is called passing in an instance of <code>NetSocket</code>. This is a socket-like interface to the actual connection, and allows you to read and write data as well as various other operations.</p>

<h5>Reading Data from the Socket</h5><br/>

<p>To read data from the socket you need to set the <code>dataHandler</code> on the socket. This handler will be called with a <code>Buffer</code> [LINK] every time data is received on the socket. You could try the following code and telnet to it to send some data:</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {

  sock.dataHandler(function(buffer) {
    log.println('I received ' + buffer.length() + ' bytes of data');
  });

}).listen(1234, 'localhost');
</pre>

<h5>Writing Data to a Socket</h5><br/>

<p>To write data to a socket, you invoke the <code>write</code> function. This function can be done in a few ways:</p>

<p>With a single buffer:</p>

<pre class="prettyprint">var myBuffer = ...
sock.write(myBuffer);
</pre>

<p>A string. In this case the string will encoded using UTF-8 and the result written to the wire.</p>

<pre class="prettyprint">sock.write('hello');
</pre>

<p>A string and an encoding. In this case the string will encoded using the specified encoding and the result written to the wire.     </p>

<pre class="prettyprint">sock.write('hello', 'UTF-16');
</pre>

<p>The <code>write</code> function is asynchronous and always returns immediately after the write has been queued. The actual write might occur some time later. If you want to be informed when the actual write has happened you can pass in a function as a final argument. This function will then be invoked when the write has completed:</p>

<pre class="prettyprint">sock.write('hello', function() {
    log.println('It has actually been written');
});
</pre>

<p>Putting it all together here's an example of a simple TCP echo server which simply writes back (echoes) everything that it receives on the socket:</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {

  sock.dataHandler(function(buffer) {
    sock.write(buffer);
  });

}).listen(1234, 'localhost');
</pre>

<h4>Closing a socket</h4><br/>

<p>You can close a socket by invoking the <code>close</code> method. This will close the underlying TCP connection.</p>

<h4>Closed Handler</h4><br/>

<p>If you want to be notified when a socket is closed, you can set the `closedHandler':</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {

    sock.closedHandler(function() {

        log.println('The socket is now closed');    

    });
});
</pre>

<p>The closed handler will be called irrespective of whether the close was initiated by the client or server.</p>

<h4>Exception handler</h4><br/>

<p>You can set an exception handler on the socket that will be called if an exception occurs:</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {

    sock.exceptionHandler(function() {

        log.println('Oops. Something went wrong');    

    });
});
</pre>

<h4>Read and Write Streams</h4><br/>

<p>NetSocket also can at as a <code>ReadStream</code> and a <code>WriteStream</code>. This allows flow control to occur on the connection and the connection data to be pumped to and from other object such as HTTP requests and responses, websockets and asynchronous files.</p>

<p>This will be discussed in depth in the chapter on streams [LINK] </p>

<h4>Scaling TCP Servers</h4><br/>

<p>A verticle instance is strictly single threaded. If I create a simple TCP server and deploy a single instance of it then all the handlers for that server are always executed on the same event loop (thread). This means that if you are running on a server with a lot of cores, and you only have this one instance deployed then you will have at most one core utilised on your server! That's not very good.</p>

<p>To remedy this you can simply deploy more instances of the verticle in the server, e.g.</p>

<pre class="prettyprint">vertx deploy echo_server.js -instances 20
</pre>

<p>Would deploy 20 instances of echo_server.js to a locally running vert.x instance. Once you do this you will find the echo server works functionally identically to before, but, as if by magic all your cores on your server can be utilised and more work can be handled.</p>

<p>By this point you might be asking yourself <em>'Hang on a second, how can you have more than one server listening on the same host and port? Surely you will get port conflicts as soon as they try and deploy more than one instance?'</em></p>

<p><em>Vert.x does a little magic here</em>. When you deploy another server on the same host and port as an existing server it doesn't actually try and create a new server listening on the same host/port, instead it internally maintains just a single server, and, as incoming connections arrive it distributes them in a round-robin fashion to any of the connect handlers set by the verticles. Consequently vert.x TCP servers can scale over available cores while each vert.x verticle instance remains strictly single threaded :)</p>

<h3>NetClient</h3><br/>

<p>A NetClient is used to make TCP connections to servers.</p>

<h4>Creating a Net Client</h4><br/>

<p>To create a TCP server we simply create an instance of vertx.net.NetClient.</p>

<pre class="prettyprint">var client = new vertx.NetClient();
</pre>

<h4>Making a Connection</h4><br/>

<p>To actually connect to a server you invoke the <code>connect</code> method:</p>

<pre class="prettyprint">var client = new vertx.NetClient();

client.connect(1234, 'localhost', function(sock) {
    log.println('We have connected');
});
</pre>

<p>The connect method takes the port number as the first parameter, followed by the hostname or ipaddress of the server. The third parameter is a connect handler. This handler will be called when the connection actually occurs.</p>

<p>The argument passed into the connect handler is an instance of <code>NetSocket</code>, exactly the same as what is passed into the server side connect handler. Once given the <code>NetSocket</code> you can read and write data from the socket in exactly the same way as you do on the server side.</p>

<p>You can also close it, set the closed handler, set the exception handler and use it as a <code>ReadStream</code> or <code>WriteStream</code> exactly the same as the server side <code>NetSocket</code>.</p>

<h4>Catching exceptions on the Net Client</h4><br/>

<p>You can set a connection handler on the NetClient. This will catch any exceptions that occur during connection.</p>

<pre class="prettyprint">var client = new vertx.NetClient();

client.exceptionHandler(function(ex) {
  log.println('Cannot connect since the host was made up!');
});

client.connect(4242, 'host-that-doesnt-exist', function(sock) {
  log.println('this won't get called');
});
</pre>

<h4>Configuring Reconnection</h4><br/>

<p>A NetClient can be configured to automatically retry connecting to the server in the event that it cannot connect or has lost its connection. This is done by invoking the functions <code>setReconnectAttempts</code> and <code>setReconnectInterval</code></p>

<pre class="prettyprint">var client = new vertx.NetClient();

client.setReconnectAttempts(1000);

client.setReconnectInterval(500);
</pre>

<p><code>ReconnectAttempts</code> determines how many times the client will try to connect to the server before giving up. A value of <code>-1</code> represents an infinite number of times.</p>

<p><code>ReconnectInterval</code> detemines how long, in milliseconds, the client will wait between reconnect attempts.</p>

<p>The default value for <code>ReconnectAttempts</code> is <code>0</code>. I.e. no reconnection is attempted.</p>

<p>If an exception handler is set on the client, and reconnect attempts is not equal to <code>0</code>. Then the exception handler will not be called until the client gives up reconnecting.</p>

<h4>NetClient Properties</h4><br/>

<p>Just like NetServer, NetClient also has a set of TCP properties you can set which affect its behaviour. They have the same meaning as those on NetServer.</p>

<p>NetServer also has a further set of properties which are used to configure SSL. We'll discuss those later on.</p>

<h3>SSL Servers</h3><br/>

<p>Net Servers can also be configured to work with <a href="http://en.wikipedia.org/wiki/Transport_Layer_Security">Transport Layer Security</a> (previously known as SSL).</p>

<p>When a Net Server is working as an SSL Server the api of the NetServer and NetSocket is identical compared to when it working with standard sockets. Getting the server to use SSL is just a matter of configuring the Net Server before listen is called.</p>

<p>To enabled ssl the function <code>setSSL(true)</code> must be called on the Net Server.</p>

<p>The server must also be configured with a <em>key store</em> and an optional <em>trust store</em>. These are both <em>Java keystores</em> which can be managed using the <a href="http://docs.oracle.com/javase/6/docs/technotes/tools/solaris/keytool.html">keytool</a> utility which ships with the JDK. keytool allows you to create keystores, and import and export certificates from them.</p>

<p>The key store should contain the server certificate. This is mandatory - the client will not be able to connect to the server over ssl if the server does not have a certificate.</p>

<p>The key store is configured on the server using the <code>setKeyStorePath</code> and <code>setKeyStorePassword</code> functions.</p>

<p>The trust store is optional and contains the certificates of any clients it should trust. This is only used if client authentication is required. </p>

<p>To configure a server to use server certificates only:</p>

<pre class="prettyprint">var server = new vertx.NetServer()
               .setSSL(true)
               .setKeyStorePath('/path/to/your/keystore/server-keystore.jks')
               .setKeyStorePassword('password');
</pre>

<p>Making sure that <code>server-keystore.jks</code> contains the server certificate.</p>

<p>To configure a server to also require client certificates:</p>

<pre class="prettyprint">var server = new vertx.NetServer()
               .setSSL(true)
               .setKeyStorePath('/path/to/your/keystore/server-keystore.jks')
               .setKeyStorePassword('password')
               .setTrustStorePath('/path/to/your/keystore/server-truststore.jks')
               .setTrustStorePassword('password')
               .setClientAuthRequired(true);
</pre>

<p>Making sure that <code>server-truststore.jks</code> contains the certificates of any clients who the server trusts. If <code>clientAuthRequired</code> is set to <code>true</code> and the client cannot provide a certificate, or it provides a certificate that the server does not trust then the connection attempt will not succeed.</p>

<h3>SSL Clients</h3><br/>

<p>Net Clients can also be easily configured to use SSL. They have the exact same api when using SSL as when using standard sockets.</p>

<p>To enable SSL on a Net Client the function <code>setSSL(true)</code> is called.</p>

<p>If the <code>setTrustAll(true)</code> is invoked on the client, then the client will trust all server certificates. The connection will still be encrypted but this mode is vulnerable to 'man in the middle' attacks. I.e. you can't be sure who you are connecting to. Use this with caution. Default value is <code>false</code>.</p>

<p>If <code>setTrustAll(true)</code> has not been invoked then a client trust store must be configured and should contain the certificates of the servers that the client trusts. The client trust store is just a standard Java key store, the same as the key stores on the server side. The client trustore location is set by using the function <code>setTrustStorePath</code> on the Net Client. If a server presents a certificate during connection which is not in the client trust store, the connection attempt will not succeed.</p>

<p>If the server requires that clients authentication is required then the client must present its own certificate to the server when connecting. This certificate should reside in the client key store. Again its just a regular Java key store. The client keystore location is set by using the function <code>setKeyStorePath</code> on the Net Client. </p>

<p>To configure a client to trust all server certificates (dangerous):</p>

<pre class="prettyprint">var client = new vertx.NetClient()
               .setSSL(true)
               .setTrustAll(true)
</pre>

<p>To configure a client to only trust those certificates it has in its trust store:</p>

<pre class="prettyprint">var client = new vertx.NetClient()
               .setSSL(true)
               .setTrustStorePath('/path/to/your/client/truststore/client-truststore.jks')
               .setTrustStorePassword('password');
</pre>

<p>To configure a client to only trust those certificates it has in its trust store, and also to supply a client certificate:</p>

<pre class="prettyprint">var client = new vertx.NetClient()
               .setSSL(true)
               .setTrustStorePath('/path/to/your/client/truststore/client-truststore.jks')
               .setTrustStorePassword('password')
               .setKeyStorePath('/path/to/keystore/holding/client/cert/client-keystore.jks')
               .setKeyStorePassword('password');
</pre>

<h2>Flow Control - Streams and Pumps</h2><br/>

<p>There are several objects in vert.x that allow data to be read from and written to in the form of Buffers. All operations in the vert.x API are non blocking, calls to write return immediately and writes are internally queued. It's not hard to see that if you write to an object faster than it can actually write the data to its underlying resource then the write queue could grow without bound eventually resulting in exhausting available memory.</p>

<p>To solve this problem a simple flow control capability is provided by some objects in the vert.x API. Any flow control aware object that can be written to is said to implement <code>ReadStream</code>, and any flow control object that can be read from is said to implement <code>WriteStream</code>.</p>

<p>Let's take an example where we want to read from one <code>ReadStream</code> and write the data to a <code>WriteStream</code>. An example would be reading from a <code>NetSocket</code> and writing to an <code>AsyncFile</code> on disk. A naive way to do this would be to directly take the data read and immediately write it to the NetSocket, as follows:</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {

  var asyncFile = vertx.FileSystem.open('some_file.dat');

  sock.dataHandler(function(buffer) {

    // Stream all data directly to the disk file:

    asyncFile.write(buffer); 
  });

}).listen(1234, 'localhost');
</pre>

<p>There's a problem with the above example: If data is read from the socket faster than it can be written to the underlying disk file, it will build up in the write queue of the AsyncFile, eventually running out of RAM.</p>

<p>It just so happens that <code>AsyncFile</code> implements <code>WriteStream</code>, so we can check if the <code>WriteStream</code> is full before writing to it:</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {

  var asyncFile = vertx.FileSystem.open('some_file.dat');

  sock.dataHandler(function(buffer) {

    // Stream all data directly to the disk file:
    if (!asyncFile.writeQueueFull()) {      
        asyncFile.writeBuffer(buffer); 
    }
  });

}).listen(1234, 'localhost');
</pre>

<p>This example won't run out of RAM but we'll end up losing data if the write queue gets full. What we really want to do is pause the <code>NetSocket</code> when the <code>AsyncFile</code> <code>WriteQueue</code> is full. Let's do that:</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {

  var asyncFile = vertx.FileSystem.open('some_file.dat');

  sock.dataHandler(function(buffer) {

    if (!asyncFile.writeQueueFull()) {      
        asyncFile.writeBuffer(buffer); 
    } else {
       sock.pause();
    }
  });

}).listen(1234, 'localhost');
</pre>

<p>We're almost there, but not quite. The <code>NetSocket</code> now gets paused when the file is full, but we also need to <em>unpause</em> it when the file write queue has processed its backlog:</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {

  var asyncFile = vertx.FileSystem.open('some_file.dat');

  sock.dataHandler(function(buffer) {

    if (!asyncFile.writeQueueFull()) {      
        asyncFile.writeBuffer(buffer); 
    } else {
       sock.pause();

       asyncFile.drainHandler(function() {
         sock.resume();
       });
    }
  });

}).listen(1234, 'localhost');
</pre>

<p>And there we have it. The <code>drainHandler</code> event handler will get called when the write queue is ready to accept more data, this resumes the <code>NetSocket</code> which allows it to read more data.</p>

<p>The above api usage pattern is common when writing vert.x applications, so we provide a helper class called <code>Pump</code> which does all this hard work for you. You just feed it that <code>ReadStream</code> and the <code>WriteStream</code> and it tell it to start:</p>

<pre class="prettyprint">var server = new vertx.NetServer();

server.connectHandler(function(sock) {

  var asyncFile = vertx.FileSystem.open('some_file.dat');

  var pump = new vertx.Pump(sock, asyncFile);

  pump.start();

}).listen(1234, 'localhost');
</pre>

<p>The above does exactly the same thing as the previous example.</p>

<p>Let's look at the methods on <code>ReadStream</code> and <code>WriteStream</code> in more detail:</p>

<h3>ReadStream</h3><br/>

<p><code>ReadStream</code> is implemented by <code>AsyncFile</code>, <code>HttpClientResponse</code>, <code>HttpServerRequest</code>, <code>WebSocket</code>, <code>NetSocket</code> and <code>SockJSSocket</code>.</p>

<p>Functions:</p>

<ul>
<li><code>dataHandler(handler)</code>: set a handler which will receive data from the <code>ReadStream</code>. As data arrives the handler will be passed a Buffer.</li>
<li><code>pause()</code>: pause the handler. When paused no data will be received in the <code>dataHandler</code>.</li>
<li><code>resume()</code>: resume the handler. The handler will be called if any data arrives.</li>
<li><code>exceptionHandler(handler)</code>: Will be called if an exception occurs on the <code>ReadStream</code>.</li>
<li><code>endHandler(handler)</code>: Will be called when end of stream is reached. This might be when EOF is reached if the <code>ReadStream</code> represents a file, or when end of request is reached if its an HTTP request, or when the connection is closed if its a TCP socket.</li>
</ul>

<h3>WriteStream</h3><br/>

<p><code>WriteStream</code> is implemented by <code>AsyncFile</code>, <code>HttpClientRequest</code>, <code>HttpServerResponse</code>, <code>WebSocket</code>, <code>NetSocket</code> and <code>SockJSSocket</code></p>

<p>Functions:</p>

<ul>
<li><code>writeBuffer(buffer)</code>: write a Buffer to the <code>WriteStream</code>. This method will never block. Writes are queued internally and asynchronously written to the underlying resource.</li>
<li><code>setWriteQueueMaxSize(size)</code>: set the number of bytes at which the write queue is considered <em>full</em>, and the function <code>writeQueueFull()</code> returns <code>true</code>. Note that, even if the write queue is considered full, if <code>writeBuffer</code> is called the data will still be accepted and queued.</li>
<li><code>writeQueueFull()</code>: returns <code>true</code> if the write queue is considered full.</li>
<li><code>exceptionHandler(handler)</code>: Will be called if an exception occurs on the <code>ReadStream</code>.</li>
<li><code>endHandler(handler)</code>: Will be called when end of stream is reached. This might be when EOF is reached if the <code>ReadStream</code> represents a file, or when end of request is reached if its an HTTP request, or when the connection is closed if its a TCP socket.</li>
</ul>

<h3>Pump</h3><br/>

<p>Instances of <code>Pump</code> have the following methods:</p>

<ul>
<li><code>start()</code>. The start the pump. When the pump is not started, the <code>ReadStream</code> is paused.</li>
<li><code>stop(). Stops the pump. Resumes the</code>ReadStream`.</li>
<li><code>setWriteQueueMaxSize()</code>. This has the same meaning as <code>setWriteQueueMaxSize</code> on the <code>WriteStream</code>.</li>
<li><code>getBytesPumped()</code>. Returns total number of bytes pumped.</li>
</ul>

<h2>Shared Data</h2><br/>

<p>Sometimes it makes sense to allow different verticles instances to share data in a safe way. vert.x allows simple <em>Map</em> and <em>Set</em> data structures to be shared between verticles.</p>

<p>There is a caveat: To prevent issues due to mutable data, vert.x only simple immutable types such as number, boolean and string, or Buffer to be used in shared data. With a Buffer, it is automatically copied when retrieved from the shared data.</p>

<p>TODO - a bit more here</p>

<p>API - atomic updates etc</p>

<h2>Writing HTTP Servers and Clients</h2><br/>

<h3>Writing HTTP servers</h3><br/>

<p>Writing full featured, highly performant and scalable HTTP servers is child's play with vert.x</p>

<h4>Creating a Net Server</h4><br/>

<p>To create an HTTP server we simply create an instance of vertx.net.HttpServer.</p>

<pre class="prettyprint">var server = new vertx.HttpServer();
</pre>

<h4>Start the Server Listening</h4><br/>

<p>To tell that server to listen on for incoming requests we do:    </p>

<pre class="prettyprint">var server = new vertx.HttpServer();

server.listen(8080, 'myhost');
</pre>

<p>The first parameter to <code>listen</code> is the port. The second parameter is the hostname or ip address. If the hostname is ommitted it will default to <code>0.0.0.0</code> which means it will listen at all available interfaces.</p>

<h4>Getting Notified of Incoming Requests</h4><br/>

<p>To be notified when a request arrives we need call the <code>requestHandler</code> function of the server, passing in a handler:</p>

<pre class="prettyprint">var server = new vertx.HttpServer();

server.requestHandler(function(request) {
  log.println('An HTTP request has been received');
})  

server.listen(8080, 'localhost');
</pre>

<p>This displays 'An HTTP request has been received!' every time am HTTP request arrives on the server. You can try it by running the verticle and pointing your browser at http://localhost:8080.</p>

<p>Similarly to Net Server, the return value of the <code>requestHandler</code> method is the server itself, so multiple invocations can be chained together. That means we can rewrite the above with:</p>

<pre class="prettyprint">var server = new vertx.HttpServer();

server.requestHandler(function(request) {
  log.println('An HTTP request has been received');
}).listen(8080, 'localhost');
</pre>

<h4>Handling HTTP Requests</h4><br/>

<p>So far we have seen how to create an HTTPServer and be notified of requests but not how to do anything interesting with the requests. </p>

<p>When a request arrives, the request handler is called passing in an instance of <code>HttpServerRequest</code>. This object represents the server side HTTP request. It contains functions to get the uri, path, request headers and request parameters. It also contains a <code>response</code> property which is a reference to an object that represents the server side HTTP response for the object.</p>

<h5>Request Method</h5><br/>

<p>The request object has a property <code>method</code> which is a string representing what HTTP method was requested. Possible values are GET, PUT, POST, DELETE, HEAD, OPTIONS, CONNECT, TRACE, PATCH.</p>

<h5>Request URI</h5><br/>

<p>The request object has a property <code>uri</code> which contains the full uri of the request. For example, if the request uri was:</p>

<pre class="prettyprint">http://localhost:8080/a/b/c/page.html?param1=abc&amp;param2=xyz
</pre>

<p>Then <code>request.uri</code> would contain the string <code>http://localhost:8080/a/b/c/page.html?param1=abc&amp;param2=xyz</code>.</p>

<h5>Request Path</h5><br/>

<p>The request object has a property <code>path</code> which contains the path of the request. For example, if the request uri was:</p>

<pre class="prettyprint">http://localhost:8080/a/b/c/page.html?param1=abc&amp;param2=xyz
</pre>

<p>Then <code>request.path</code> would contain the string <code>/a/b/c/page.html</code></p>

<h5>Request Query</h5><br/>

<p>The request object has a property <code>query</code> which contains the query of the request. For example, if the request uri was:</p>

<pre class="prettyprint">http://localhost:8080/a/b/c/page.html?param1=abc&amp;param2=xyz
</pre>

<p>Then <code>request.query</code> would contain the string <code>param1=abc&amp;param2=xyz</code>    </p>

<h5>Request Headers</h5><br/>

<p>The request headers are available using the <code>headers()</code> function on the request object. The return value of the function is just a JavaScript hash. Here's an example that echoes the headers to the output of the response. Run it and point your browser at http://localhost:8080 to see the headers.</p>

<pre class="prettyprint">var server = new vertx.HttpServer();

server.requestHandler(function(request) {

  var headers = request.headers();  

  var str = '';
  for (var k in headers) {
    str = str.concat(k, ': ', headers[k], '\n');
  }

  request.response.end(str);

}).listen(8080, 'localhost');
</pre>

<h5>Request params</h5><br/>

<p>Similarly to the headers, the request parameters are available using the <code>params()</code> function on the request object. The return value of the function is just a JavaScript hash.     </p>

<p>Request parameters are sent on the request uri, after the path. For example if the uri was:</p>

<pre class="prettyprint">http://localhost:8080/page.html?param1=abc&amp;param2=xyz
</pre>

<p>Then the params hash would be the following object:</p>

<pre class="prettyprint">{ param1: 'abc', param2: 'xyz' }
</pre>

<h5>Reading Data from the Request Body</h5><br/>

<p>Sometimes an HTTP request contains a request body that we want to read. The request body is not passed fully read with the HTTP request since it may be very large and we don't want to have problems with available memory.</p>

<p>Instead you set a <code>dataHandler</code> on the request object which gets called as parts of the HTTP request arrive. Here's an example:</p>

<pre class="prettyprint">var server = new vertx.HttpServer();

server.requestHandler(function(request) {

  request.dataHandler(function(buffer) {
    log.println('I received ' + buffer.length() + ' bytes');
  });

}).listen(8080, 'localhost');
</pre>

<p>The request object implements the <code>ReadStream</code> interface so you can pump the request body to a <code>WriteStream</code>. See the chapter on streams and pump for a detailed explanation. You'll notice this is very similar to how data from NetSocket is read.   </p>

<p>If you wanted to read the entire request body before doing something with it you could do something like the following:</p>

<pre class="prettyprint">var server = new vertx.HttpServer();

server.requestHandler(function(request) {

  var body = new vertx.Buffer();  

  request.dataHandler(function(buffer) {
    body.appendBuffer(buffer);
  });

  request.endHandler(function() {
    log.println('The total body received was ' + body.length() + ' bytes');
  });

}).listen(8080, 'localhost');
</pre>

<p>Like any <code>ReadStream</code> the end handler is invoked when the end of stream is reached - in this case at the end of the request.</p>

<p>If the HTTP request is using HTTP chunking, then each chunk of the request body will be received in a different call ti the data handler.</p>

<p>Since it's such a common use case to want to read the entire body before processing it, vert.x allows a <code>bodyHandler</code> to be set on the request object. The body handler does is called when the <em>entire</em> request body has been read. Beware of doing this with very large requests since the entire request body will be stored in memory.</p>

<p>Here's an example using <code>bodyHandler</code>:</p>

<pre class="prettyprint">var server = new vertx.HttpServer();

server.requestHandler(function(request) {

  request.bodyHandler(function(body) {
    log.println('The total body received was ' + body.length() + ' bytes');
  });

}).listen(8080, 'localhost');
</pre>

<h4>Writing HTTP Responses</h4><br/>

<p>As previously mentioned, the HTTP request object contains a property <code>response</code>. This is the HTTP response for the request. You use it to write the response back to the client.</p>

<p>To write data to an http response, you invoke the <code>write</code> function. This function can be invoked in a few ways:</p>

<p>With a single buffer:</p>

<pre class="prettyprint">var myBuffer = ...
request.response.write(myBuffer);
</pre>

<p>A string. In this case the string will encoded using UTF-8 and the result written to the wire.</p>

<pre class="prettyprint">request.response.write('hello');
</pre>

<p>A string and an encoding. In this case the string will encoded using the specified encoding and the result written to the wire.     </p>

<pre class="prettyprint">request.response.write('hello', 'UTF-16');
</pre>

<p>The <code>write</code> function is asynchronous and always returns immediately after the write has been queued. The actual write might occur some time later. If you want to be informed when the actual write has happened you can pass in a function as a final argument. This function will then be invoked when the write has completed:</p>

<pre class="prettyprint">request.response.write('hello', function() {
    log.println('It has actually been written');
});
</pre>

<p>If you are just writing a single string or Buffer to the HTTP response you can write it and end the response in a single call to the <code>end</code> function.   </p>

<p>The first call to <code>write</code> results in the response header being being written to the response. Consequently, if you are not using HTTP chunking then you must set the <code>Content-Length</code> header before writing to the response, since it will be too late otherwise. If you are using HTTP chunking you do not have to worry. </p>

<h4>Ending HTTP responses</h4><br/>

<p>Once you have finished with the HTTP response you must call the <code>end()</code> function on it.</p>

<p>This function can be invoked in several ways:</p>

<p>With no arguments, the response is simply ended. </p>

<pre class="prettyprint">request.response.end();
</pre>

<p>The function can also be called with a string or Buffer in the same way <code>write</code> is called. In this case it's just the same as calling write with a string or Buffer followed by calling <code>end</code> with no arguments.</p>

<p>You can also optionally call <code>end</code> with a final boolean argument. If this argument is <code>true</code> then the underlying connection will be closed when the response has been written, otherwise the underlying connection will be left open.</p>

<h4>Response headers</h4><br/>

<p>Individual response headers can be written using the <code>putHeader</code> method. For example:</p>

<pre class="prettyprint">request.response.putHeader('Content-Length', '0');
</pre>

<p>Response headers must all be added before any parts of the response body are written.</p>

<p>If you wish to add several headers in one operation, just call <code>putHeaders</code> with a hash of the headers:</p>

<pre class="prettyprint">request.response.putHeaders({ 'Content-Length' : '0', 'Some-Other-Header': 'abc'});
</pre>

<h4>Chunked HTTP Responses and Trailers</h4><br/>

<p>vert.x also supports <a href="http://en.wikipedia.org/wiki/Chunked_transfer_encoding">HTTP Chunked Transfer Encoding</a>. This allows the HTTP response body to be written in chunks, and is normally used when a large response body is being streamed to a client, whose size is not known in advance.</p>

<p>You put the HTTP response into chunked mode as follows:</p>

<pre class="prettyprint">req.response.setChunked(true);
</pre>

<p>Default is non-chunked. When in chunked mode, each call to <code>response.write(...)</code> will result in a new HTTP chunk being written out.  </p>

<p>When in chunked mode you can also write HTTP response trailers to the response. These are actually written in the final chunk of the response.  </p>

<p>To write an individual trailer use the <code>putTrailer</code> method:</p>

<pre class="prettyprint">request.response.putTrailer('Some-Trailer', 'some value');
</pre>

<p>If you wish to add several trailers in one operation, just call <code>putTrailers</code> with a hash of the trailers:</p>

<pre class="prettyprint">request.response.putTrailers({ 'Some-Trailer' : 'some value', 'Some-Other-Trailer': 'wibble'});
</pre>

<h4>Serving files directly disk</h4><br/>

<p>You could stream a file from disk to a HTTP response by opening an <code>AsyncFile</code> using the file system and pumping it to the response, or you could load it in one go using the file system and write that to the response.</p>

<p>Alternatively, vert.x provides a feature where you can stream files directly from disk to the response bypassing userspace altogether. This functionality is OS dependent and leverages the <code>sendfile</code> operation to tell the kernel to directly serve the file. Using this operation can greatly reduce CPU utilisation.</p>

<p>To do this use the <code>sendfile</code> function on the HTTP response, for example here's a simple HTTP web server that serves static files from the local <code>web</code> directory:</p>

<pre class="prettyprint">var server = new vertx.HttpServer();

server.requestHandler(function(req) {
  var file = '';
  if (req.path == '/') {
    file = 'index.html';
  } else if (req.path.indexOf('..') == -1) {
    file = req.path;
  }
  req.response.sendFile('web/' + file);   
}).listen(8080, 'localhost');
</pre>

<p><strong>If you're going to write web servers using vert.x be careful that users can exploit the path to access files outside the directory from which you want to serve them.</strong></p>

<h4>Pumping Responses</h4><br/>

<p>Since the HTTP Response implements <code>WriteStream</code> you can pump to it from any <code>ReadStream</code>, e.g. an <code>AsyncFile</code>, <code>NetSocket</code> or <code>HttpServerRequest</code>. Here's an example which simply echoes an HttpRequest headers and body back in the HttpResponse. Since it uses a pump for the body, it will work even if the HTTP request body is much larger than can fit in memory at any one time:</p>

<pre class="prettyprint">var server = new vertx.HttpServer();

server.requestHandler(function(req) {

  req.response.putHeaders(req.headers());

  var p = new Pump(req, req.response);
  p.start();

}).listen(8080, 'localhost');
</pre>

<h3>Writing HTTP Clients</h3><br/>

<h4>Creating an HTTP Client</h4><br/>

<p>To create an HTTP client you simply create an instance of vertx.HttpClient</p>

<pre class="prettyprint">var client = new vertx.HttpClient();
</pre>

<p>You can set the port and hostname (or ip address) that the client will connect to be using the <code>setHost</code> and <code>setPort</code> functions:</p>

<pre class="prettyprint">var client = new vertx.HttpClient();
client.setPort(8181);
client.setHost('foo.com');
</pre>

<p>This, of course can be chained:</p>

<pre class="prettyprint">var client = new vertx.HttpClient()
               .setPort(8181);
               .setHost('foo.com');
</pre>

<p>A single http client always connects to the same host and port. If you want to connect to different servers, create more instances of http client.</p>

<p>The default value for hostname is <code>localhost</code>, and the default value for port is <code>80</code>.  </p>

<h4>Pooling and Keep Alive</h4><br/>

<p>By default the HTTP client pools HTTP connections. As you make requests a connection is borrowed from the pool and returned when the HTTP response returns.</p>

<p>If you do not want connections to be pooled you can set keep alive to false on the pool:</p>

<pre class="prettyprint">var client = new vertx.HttpClient()
               .setPort(8181);
               .setHost('foo.com').
               .setKeepAlive(false);
</pre>

<p>In this case a new connection will be created for each HTTP request and closed once the response has returned.</p>

<p>You can set the maximum number of connections that the client will pool as follows:</p>

<pre class="prettyprint">var client = new vertx.HttpClient()
               .setPort(8181);
               .setHost('foo.com').
               .setMaxPoolSize(10);
</pre>

<p>The default value is 1.         </p>

<h4>Closing the client</h4><br/>

<p>Once you have finished with an HTTP client, you should close it:</p>

<pre class="prettyprint">client.close();
</pre>

<h4>Making Requests</h4><br/>

<p>To make a request using the client you invoke one the methods named after the HTTP methods. For example, to make a POST request:</p>

<pre class="prettyprint">var client = new vertx.HttpClient();

var request = client.post('http://localhost:8080/some-uri', function(resp) {
    log.println('Got a response, status code: ' + resp.statusCode);
});

request.end();
</pre>

<p>To make a PUT request use the <code>put</code> method, to make a GET request use the <code>get</code> method, etc.</p>

<p>The general modus operandi is you invoke the appropriate method passing in the request URI as the first parameter, the second parameter is an event handler which will get called when the corresponding response arrives. The response handler is passed the client response object as an argument.</p>

<p>The return value from the appropriate request method is a client request object. You can use this to add headers to the request, and to write to the request body.</p>

<p>Once you have finished with the request you must call the <code>end</code> function.</p>

<p>If you don't know the name of the request method in advance there is a general request method which takes the method name as a parameter:</p>

<pre class="prettyprint">var client = new vertx.HttpClient();

var request = client.request('POST', 'http://localhost:8080/some-uri', function(resp) {
    log.println('Got a response, status code: ' + resp.statusCode);
});

request.end();
</pre>

<p>There is a method called <code>getNow</code> which does the same as <code>get</code>, but automatically ends the request. This is useful for simple GETs which don't have a request body:</p>

<pre class="prettyprint">var client = new vertx.HttpClient();

client.getNow('http://localhost:8080/some-uri', function(resp) {
    log.println('Got a response, status code: ' + resp.statusCode);
});
</pre>

<p>With <code>getNow</code> there is no return value.</p>

<h5>Writing to the request body</h5><br/>

<p>Writing to the client request body has a very similar API to writing to the server response body.</p>

<p>To write data to an http client request, you invoke the <code>write</code> function. This function can be invoked in a few ways:</p>

<p>With a single buffer:</p>

<pre class="prettyprint">var myBuffer = ...
request.write(myBuffer);
</pre>

<p>A string. In this case the string will encoded using UTF-8 and the result written to the wire.</p>

<pre class="prettyprint">request.write('hello');
</pre>

<p>A string and an encoding. In this case the string will encoded using the specified encoding and the result written to the wire.     </p>

<pre class="prettyprint">request.write('hello', 'UTF-16');
</pre>

<p>The <code>write</code> function is asynchronous and always returns immediately after the write has been queued. The actual write might occur some time later. If you want to be informed when the actual write has happened you can pass in a function as a final argument. This function will then be invoked when the write has completed:</p>

<pre class="prettyprint">request.response.write('hello', function() {
    log.println('It has actually been written');
});
</pre>

<p>If you are just writing a single string or Buffer to the HTTP request you can write it and end the request in a single call to the <code>end</code> function.   </p>

<p>The first call to <code>write</code> results in the request header being being written to the request. Consequently, if you are not using HTTP chunking then you must set the <code>Content-Length</code> header before writing to the request, since it will be too late otherwise. If you are using HTTP chunking you do not have to worry. </p>

<h4>Ending HTTP requests</h4><br/>

<p>Once you have finished with the HTTP request you must call the <code>end</code> function on it.</p>

<p>This function can be invoked in several ways:</p>

<p>With no arguments, the response is simply ended. </p>

<pre class="prettyprint">request.end();
</pre>

<p>The function can also be called with a string or Buffer in the same way <code>write</code> is called. In this case it's just the same as calling write with a string or Buffer followed by calling <code>end</code> with no arguments.</p>

<p>You can also optionally call <code>end</code> with a final boolean argument. If this argument is <code>true</code> then the underlying connection will be closed when the response has been written, otherwise the underlying connection will be left open.</p>

<h5>Writing Request Headers</h5><br/>

<p>To write headers to the request, use the <code>putHeader</code> method.</p>

<pre class="prettyprint">var client = new vertx.HttpClient();

var request = client.post('http://localhost:8080/some-uri', function(resp) {
    log.println('Got a response, status code: ' + resp.statusCode);
});

request.putHeader('Some-Header', 'Some-Value');
</pre>

<p>These can be chained together as per the common vert.x API pattern:</p>

<pre class="prettyprint">client.post('http://localhost:8080/some-uri', function(resp) {
    log.println('Got a response, status code: ' + resp.statusCode);
}).putHeader('Some-Header', 'Some-Value')
  .putHeader('Some-Other-Header', 'Some-Other-Value')
  .end();
</pre>

<p>If you want to put more than one header at the same time, you can instead use the <code>putHeaders</code> function.</p>

<p>client.post('http://localhost:8080/some-uri', function(resp) {
        log.println('Got a response, status code: ' + resp.statusCode);
    }).putHeaders({'Some-Header': 'Some-Value',
                   'Some-Other-Header': 'Some-Other-Value'})
      .end(); </p>

<p><strong>[[ TODO putHeaders currently not implemented ]]</strong></p>

<h5>HTTP chunked requests</h5><br/>

<p>vert.x also supports <a href="http://en.wikipedia.org/wiki/Chunked_transfer_encoding">HTTP Chunked Transfer Encoding</a> for requests. This allows the HTTP request body to be written in chunks, and is normally used when a large request body is being streamed to the server, whose size is not known in advance.</p>

<p>You put the HTTP request into chunked mode as follows:</p>

<pre class="prettyprint">request.setChunked(true);
</pre>

<p>Default is non-chunked. When in chunked mode, each call to <code>request.write(...)</code> will result in a new HTTP chunk being written out.  </p>

<h5>Reading Data from the Response Body</h5><br/>

<p>The api for reading a client http response body is very similar to the api for read a server http request body.</p>

<p>Sometimes an HTTP response contains a request body that we want to read. The response body is not passed fully read with the HTTP response since it may be very large and we don't want to have problems with available memory.</p>

<p>Instead you set a <code>dataHandler</code> on the response object which gets called as parts of the HTTP response arrive. Here's an example:</p>

<pre class="prettyprint">var client = new vertx.HttpClient();

client.getNow('http://localhost:8080/some-uri', function(resp) {
  resp.dataHandler(function(buffer) {
    log.println('I received ' + buffer.length() + ' bytes');
  });    
});
</pre>

<p>The response object implements the <code>ReadStream</code> interface so you can pump the response body to a <code>WriteStream</code>. See the chapter on streams and pump for a detailed explanation. </p>

<p>If you wanted to read the entire response body before doing something with it you could do something like the following:</p>

<pre class="prettyprint">var client = new vertx.HttpClient();

client.getNow('http://localhost:8080/some-uri', function(resp) {

  var body = new vertx.Buffer();  

  resp.dataHandler(function(buffer) {
    body.appendBuffer(buffer);
  });

  resp.endHandler(function() {
    log.println('The total body received was ' + body.length() + ' bytes');
  });

});
</pre>

<p>Like any <code>ReadStream</code> the end handler is invoked when the end of stream is reached - in this case at the end of the response.</p>

<p>If the HTTP response is using HTTP chunking, then each chunk of the response body will be received in a different call to the data handler.</p>

<p>Since it's such a common use case to want to read the entire body before processing it, vert.x allows a <code>bodyHandler</code> to be set on the response object. The body handler is called when the <em>entire</em> response body has been read. Beware of doing this with very large responses since the entire response body will be stored in memory.</p>

<p>Here's an example using <code>bodyHandler</code>:</p>

<pre class="prettyprint">var client = new vertx.HttpClient();

client.getNow('http://localhost:8080/some-uri', function(resp) {

  resp.bodyHandler(function() {
    log.println('The total body received was ' + body.length() + ' bytes');
  });

});
</pre>

<h4>Pumping Responses</h4><br/>

<p>Like several other objects in vert.x, the HTTP client request implements <code>WriteStream</code> you can pump to it from any <code>ReadStream</code>, e.g. an <code>AsyncFile</code>, <code>NetSocket</code> or <code>HttpServerRequest</code>. Here's a very simple proxy server which forwards a request to another server and forwards the response back to the client. It uses two pumps - one to pump the server request to the client request, and another to pump the client response back to the server response. Since it uses pumps it will work even if the HTTP request body is much larger than can fit in memory at any one time:</p>

<pre class="prettyprint">var server = new vertx.HttpServer();

var client = new vertx.HttpClient().setHost('some-other-server.com');

server.requestHandler(function(req) {

    var clientReq = client.request(req.method, req.uri, function(clientResp) {

        req.response.status_code = clientResp.statusCode;
        req.response.putAllHeaders(clientResp.headers());

        var respPump = new Pump(clientResp, req.response);
        respPump.start();

        clientResp.endHandler(function() { req.response.end() });
    }

    clientReq.putAllHeaders(req.headers());

    var reqPump = new Pump(req, clientReq);

    reqPump.start();

    req.endHandler(function { clientReq.end() } );

}).listen(8080, 'localhost');
</pre>

<h3>100-Continue Handling</h3><br/>

<p>According to the [HTTP 1.1 specification] (http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html) a client can set a header <code>Expect: 100-Continue</code> and send the request header before sending the rest of the request body. The server can then respond with an interim response status <code>Status: 100 (Continue)</code> to signify the client is ok to send the rest of the body. The idea here is it allows the server to reject the request before large amounts of data has already been sent, which would be a waste of bandwidth.</p>

<p>The vert.x allows you to set a continue handler on the client request object. This will be called if the server sends back a <code>Status: 100 (Continue)</code> response to signify it is ok to send the rest of the request. This is used in conjunction with the <code>sendHead</code> function to send the head of the request.</p>

<p>An example will illustrate this:</p>

<pre class="prettyprint">var client = new vertx.HttpClient();

var request = client.put('http://localhost:8080/some-uri', function(resp) {

  resp.bodyHandler(function(resp) {
    log.println('Got a response ' + resp.statusCode);
  });

});     

request.putHeader('Expect', '100-Continue');

request.continueHandler(function() {
    // OK to send rest of body

    request.write('Some data').end();
});

request.sendHead();
</pre>

<h3>HTTPS Servers</h3><br/>

<p>HTTP Servers can also be configured to work with <a href="http://en.wikipedia.org/wiki/Transport_Layer_Security">Transport Layer Security</a> (previously known as SSL).</p>

<p>When an HTTP Server is working as an HTTPS Server the api of the server is identical compared to when it working with standard HTTP. Getting the server to use HTTPS is just a matter of configuring the HTTP Server before listen is called.</p>

<p>Configuration of an HTTPS server is exactly the same as configuring a Net Server for SSL. Please see SSL server chapter for detailed instructions.</p>

<h3>HTTPS Clients</h3><br/>

<p>HTTP Clients can also be easily configured to use HTTPS.</p>

<p>Configuration of an HTTPS client is exactly the same as configuring a Net Client for SSL. Please see SSL client chapter for detailed instructions. </p>

<h3>Scaling HTTP servers</h3><br/>

<p>Scaling an HTTP server over multiple cores is as simple as deploying more instances of the verticle. For example:</p>

<pre class="prettyprint">vertx deploy http_server.js -instances 20
</pre>

<p>The scaling works in the same way as scaling a Net Server. Please see the section on scaling Net Servers for a detailed explanation [LINK].    </p>

<h2>WebSockets</h2><br/>

<p><a href="http://en.wikipedia.org/wiki/WebSocket">WebSockets</a> are a new feature in HTML 5 that allows a full duplex socket-like connection between HTTP servers and HTTP clients (typically browsers).</p>

<p>vert.x implements the most common versions of websockets on both the server and client side.</p>

<p>[[VERSION NUMBERS]]</p>

<h3>WebSockets on the server</h3><br/>

<h3>WebSockets on the HTTP client</h3><br/>

<h3>WebSockets in the browser</h3><br/>

<h2>SockJS</h2><br/>
</div>
    </div>
  </div>

  <hr>

  <footer>
    <p>&copy; VMware 2012</p>
  </footer>

</div>
<!-- /container -->

<!-- Le javascript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="../assets/js/tests/vendor/jquery.js"></script>
<script src="../assets/js/bootstrap-transition.js"></script>
<script src="../assets/js/bootstrap-collapse.js"></script>

</body>
</html>
